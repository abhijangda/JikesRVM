# Distributed JikesRVM profiling experiments

The experimental platform described here, residing on the experiments branch and
in the `experiments` folder, aims to make the published experiments
reproducible. Each experiment is normally run on a fresh build of jikes, using a
specified git commit hash or branch.

## Infrastructure

A Vagrantfile is provided in the experiments directory to document the setup of
build dependencies and such. This is currently configured to use 4 GB of memory
and four virtual CPU cores, using the VirtualBox provider.

Start up the virtual machine and log into it using the normal vagrant commands.
When finished, the VM can be stopped with `vagrant halt` and deleted with
`vagrant destroy`.

```
cd experiments
vagrant up
vagrant ssh
```

After logging in, a checkout of our Jikes repository is available in
`~/JikesRVM/`. This is a shared folder between the VM and the host machine, so
compilation artifacts may be left in it after provisioning the VM, and these
must be maintained for the benchmarks to run.

## Fully Automated Runs

The full experimental scripts in `experiments/` of the form
`<n>_<experiment-name>.py` can be run as is and will produce CSV files, which
can later be used by the graph creation scripts.

As each experiment may require code from a different branch, these scripts will
clone the repository, check out a specified commit, and rebuild the Jikes
binaries before starting the experiments. They will also download the dacapo.jar
file if it does not already exist.

Each experiment script includes a default number of repetitions corresponding to
that used in generating code for our published graphs. This can be overridden by
specifying a number as the first argument to the script.

Example:

```
cd experiments/
python 1_naive_overhead.py 10
```

## Graphs

Our graphs are generated with matplotlib. This might require installation of
matplotlib and numpy through the python pacakage manager.

Once benchmark results have been generated by the automated run scripts, the
corresponding graph script uses the resulting CSV files to do the required data
analysis and produce the graph itself.

```
cd experiments/
python graph_1.py
```

This will use the csv files in `results/` to create the graph in `figures/1_naive_overhead.pdf`.

_The exact naming of the graph and benchmark scripts needs to be thought out still and is subject to change._

## Manual Experimental Runs

Use a python shell and the common module provided in `experiments/`.

The example provided below will run a single benchmark with the provided vm
flags, assuming the correct version of the Jikes binaries already exists in the
current repository - that is, no additional checkout or build will be performed.

```
cd experiments/
python
> import common
> common.reset_root()
> common.run_dacapo('avrora', vm_args=['-use_aosdb'])
```

The `run_dacapo` method returns the runtime in milliseconds as reported by the dacapo benchmark harness.
